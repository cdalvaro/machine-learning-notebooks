{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STRIPS Action Model\n",
    "\n",
    "En este notebook se implementa un planificador basado en _STRIPS_ que permita a un mono situado en una posici贸n cualquiera alcanzar unos pl谩tanos colgados del techo mediante el uso de una caja que podr谩 desplazar por el suelo para subirse a ella y coger los pl谩tanos.\n",
    "\n",
    "Las reglas son:\n",
    "\n",
    "- Para alcanzar los pl谩tanos el mono debe subirse a la caja cuando la caja y 茅ste est茅n en la misma posici贸n que los pl谩tanos.\n",
    "- El mono puede empujar la caja cuando se encuentra en el suelo y en la misma posici贸n que la caja.\n",
    "- El mono no puede desplazarse horizontalmente cuando est谩 subido sobre la caja.\n",
    "\n",
    "![](./STRIPS.svg)\n",
    "\n",
    "Las clases y m茅todos usados en el notebook para resolver la planificaci贸n pueden encontrarse en el paquete de Python ([`cdalvaro`](cdalvaro)) anexo a este documento.\n",
    "\n",
    "Es paquete modeliza las propiedades ([`properties`](cdalvaro/properties)) de los estados ([`State`](cdalvaro/state.py)) y las acciones ([`actions`](cdalvaro/actions)) que se pueden realizar con la l贸gica y restricciones del problema.\n",
    "\n",
    "Por otro lado, las clases [`Heuristic`](cdalvaro/heuristic.py) y [`Strips`](cdalvaro/strips.py) contienen la l贸gica para la b煤squeda de la planificaci贸n que permita al mono alcanzar el pl谩tano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla de Contenidos\n",
    "\n",
    "- [Condici贸n inicial](#Condici贸n-inicial)\n",
    "- [Generaci贸n de la planificaci贸n](#Generaci贸n-de-la-planificaci贸n)\n",
    "- [Plan encontrado](#Plan-encontrado)\n",
    "- [Algoritmo STRIPS](#Algoritmo-STRIPS)\n",
    "- [Heur铆stica del problema](#Heur铆stica-del-problema)\n",
    "- [Pesos de acciones y propiedades](#Pesos-de-acciones-y-propiedades)\n",
    "  - [Pesos de acciones](#Pesos-de-acciones)\n",
    "  - [Pesos de propiedades](#Pesos-de-propiedades)\n",
    "- [Acciones](#Acciones)\n",
    "- [Propiedades](#Propiedades)\n",
    "- [Conclusiones](#Conclusiones)\n",
    "  - [Condici贸n inicial alternativa 1](#Condici贸n-inicial-alternativa-1)\n",
    "  - [Condici贸n inicial alternativa 2](#Condici贸n-inicial-alternativa-2)\n",
    "  - [Condici贸n inicial alternativa 3](#Condici贸n-inicial-alternativa-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condici贸n inicial\n",
    "\n",
    "Comenzamos por definir la condici贸n inicial del problema y el objetivo a alcanzar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdalvaro.element import Banana, Box, Monkey\n",
    "from cdalvaro.properties import GroundLevel, TopLevel, AtLevel, AtPosition, Has\n",
    "from cdalvaro.state import State\n",
    "\n",
    "initial_state = State({\n",
    "    AtPosition(Monkey(), 1),\n",
    "    AtLevel(Monkey(), GroundLevel()),\n",
    "    AtPosition(Banana(), 2),\n",
    "    AtPosition(Box(), 3)\n",
    "})\n",
    "\n",
    "goal_state = State({\n",
    "    Has(Monkey(), Banana())\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta primera parte se definen las condiciones iniciales del problema, donde se establecen la posici贸n y nivel del mono, y las posiciones de la caja y del pl谩tano. No es necesario establecer los niveles de los dos 煤ltimos, dado que est谩n fijados por las restricciones del problema. Los pl谩tanos siempre est谩n en el nivel superior, y la caja siempre est谩 en el nivel inferior.\n",
    "\n",
    "As铆, las condiciones de inicio del problema son:\n",
    "\n",
    "- El mono est谩 situado en la posici贸n 1: `AtPosition(Monkey(), 1)`\n",
    "- El mono est谩 en el nivel inferior: `AtLevel(Monkey(), GroundLevel())`\n",
    "- El pl谩tano est谩 en la posici贸n 2: `AtPosition(Banana(), 2)`\n",
    "- La caja est谩 en la posici贸n 3: `AtPosition(Box(), 3)`\n",
    "\n",
    "Para el estado objetivo, cabe destacar la simplicidad del estado: `Has(Monkey(), Banana())`. _El mono tiene el pl谩tano_.\n",
    "\n",
    "No se requiere definir m谩s propiedades del estado final, dado que ya vienen determinadas por la inmutabilidad de la propiedad de posici贸n del pl谩tano en la condici贸n inicial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generaci贸n de la planificaci贸n\n",
    "\n",
    "Con el estado inicial y final ya definidos, se crean una instancia de `Heuristic` y otra de `Strips` que conjuntamente generar谩n el plan para que el mono alcance el pl谩tano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdalvaro.actions import BaseAction\n",
    "from cdalvaro.heuristic import Heuristic\n",
    "from cdalvaro.strips import Strips\n",
    "\n",
    "BaseAction.verbose = False\n",
    "\n",
    "planner = Strips(initial_state, goal_state, Heuristic(initial_state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clase [`Heuristic`](cdalvaro/heuristic.py) implementa los m茅todos:\n",
    "\n",
    "- `possible_actions(state: State) -> Actions`: genera todas las posibles acciones disponibles en el escenario, y tiene en cuenta el estado para construir la acci贸n de conseguir el pl谩tano. (Usa `state` para determinar si en ese estado es posible la acci贸n de conseguir el pl谩tano).\n",
    "- `choose_actions(self, state: State, goal: State) -> Actions`: devuelve ordenadas de m谩s efectiva a menos efectiva las acciones que llevan del estado `state` al estado `goal`.\n",
    "- `sort_properties(properties: Properties) -> List[BaseProperty]`: ordena las propiedades indicadas en base al peso de cada propiedad.\n",
    "\n",
    "(En la secci贸n [_Pesos de acciones y propiedades_](#Pesos-de-acciones-y-propiedades) se detalla en qu茅 consisten estos pesos y el criterio de asignaci贸n.)\n",
    "\n",
    "La clase [`Strips`](cdalvaro/strips.py) por su parte, implementa el m茅todo: `get_plan(self) -> Union[Actions, bool]`, que devuelve la planificaci贸n encontrada con la lista de acciones a realizar para que el mono consiga el pl谩tano, o `False` si no se consigue encontrar una planificaci贸n.\n",
    "\n",
    "Este m茅todo parte del estado objetivo determinando las acciones en sentido inverso que habr铆a que aplicar para llegar al estado inicial. (El plan devuelto por el algoritmo s铆 est谩 en el orden de aplicaci贸n correcto para aplicarlo sobre el estado inicial).\n",
    "\n",
    "En el apartado [Algoritmo STRIPS](#Algoritmo-STRIPS) se describe el c贸digo que calcula la planificaci贸n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan encontrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Plan encontrado \n  1. Mueve  de 1 a 3\n  2.  empuja la  de 3 a 2\n  3. Cambia  al nivel Superior en posici贸n 2\n  4.  consigue  en posici贸n 2\n"
    }
   ],
   "source": [
    "def get_plan(planner: Strips, optimal_solution: bool = True):\n",
    "    \"\"\"\n",
    "    M茅todo auxiliar para mejorar la legibilidad del documento.\n",
    "    Muestra la planificaci贸n obtenida usando un planificador basado en STRIPS.\n",
    "    \n",
    "    Args:\n",
    "        planner (Strips): Planificador usado para calcular la planificaci贸n.\n",
    "        optimal_solution (bool, optional): Flag para activar/desactivar la b煤squeda del plan 贸ptimo. Default: True.\n",
    "    \"\"\"\n",
    "    Strips.efficiency_limit = 10 if optimal_solution else 0\n",
    "    plan = planner.get_plan()\n",
    "    if not plan:\n",
    "        print(\"No se ha conseguido eleborar un plan que resuelva el problema \")\n",
    "    else:\n",
    "        print(\"Plan encontrado \")\n",
    "        for it, action in zip(range(1, len(plan) + 1), plan):\n",
    "            print(f\"  {it}. {action}\")\n",
    "\n",
    "get_plan(planner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo STRIPS\n",
    "\n",
    "A continuaci贸n se describe el algoritmo implementado en el m茅todo [`get_plan()`](cdalvaro/strips.py) de la clase `Strips`. (Se recomienda leer esta descripci贸n con el c贸digo en paralelo).\n",
    "\n",
    "- El algoritmo obtiene una lista de objetivos (`targets`) compuesta por las propiedades del estado `goal` e inicializa su estado _actual_ (`state`) al estado de partida del problema.\n",
    "\n",
    "- A continuaci贸n comienza a iterar sobre `targets` hasta que no queden m谩s en la lista.\n",
    "\n",
    "- En cada iteraci贸n se extrae el primer elemento de la lista (`target`) y se comprueba si se trata de una acci贸n ([`BaseAction`](cdalvaro/actions/base_action.py)) o si por el contrario es una propiedad ([`BaseProperty`](cdalvaro/properties/base_property.py)).\n",
    "\n",
    "- Si `target` es una acci贸n, se comprueba si 茅sta puede generar un estado v谩lido a partir del estado actual `state`. Si es as铆, se actualiza `state` al nuevo estado y la acci贸n se a帽ade al plan.\n",
    "\n",
    "- Si `target` es una propiedad, se comprueba si esta propiedad pertenece a las propiedades del estado actual. Si se cumple la condici贸n, se ignora la propiedad y se contin煤a explorando el resto de objetivos de la lista.\n",
    "\n",
    "- Si `target` es una propiedad y no se encuentra entre las propiedades del estado que se est谩 analizando, se procede a buscar las acciones que pueden dar lugar desde el estado actual `state` a un estado que contiene la propiedad `target` que se est谩 evaluando.\n",
    "\n",
    "- Esta lista de posibles acciones la genera la heur铆stica con el m茅todo [`choose_actions`](cdalvaro/heuristic.py) que est谩 detallado en la secci贸n [Heur铆stica del problema](#Heur铆stica-del-problema).\n",
    "\n",
    "- Las acciones devueltas por la heur铆stica vienen ordenadas de mayor a menor peso. Es decir, de m谩s a menos 贸ptima.\n",
    "\n",
    "- Se comprueba si la lista de acciones devuelta por la heur铆stica est谩 vac铆a. De ser as铆, no es posible alcanzar el estado objetivo y no se consigue encontrar la planificaci贸n buscada, por lo que se acaba devolviendo `False`.\n",
    "\n",
    "- Si la lista de acciones no est谩 vac铆a, se selecciona la primera acci贸n de la lista (por ser la m谩s eficiente) y se inserta como primer elemento de la lista de `targets`. Adem谩s se insertan en la lista de objetivos, tambi茅n por delante, las precondiciones de la acci贸n seleccionada para buscar las acciones que puedan llevar a aplicar posteriormente la acci贸n encontrada.\n",
    "\n",
    "- Por 煤ltimo, se implementa un mecanismo de seguridad para evitar caer en b煤cles infinitos. Si pasados `10` ciclos de b煤squeda de acciones no se ha llegado al final del plan, se elimina el orden de acciones devuelto por la heur铆stica desordenando aleatoriamente la lista de acciones obtenida. De este modo, aunque el plan tarde m谩s en converger y no sea 贸ptimo acabar谩 encontrando una combinanci贸n de acciones que resuelva el plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heur铆stica del problema\n",
    "\n",
    "La heur铆sitica que se encarga de identificar las acciones posibles y de determinar cu谩l es la m谩s eficiente se encuentra en la clase [`Heuristic`](cdalvaro/heuristic.py).\n",
    "\n",
    "Esta clase est谩 compuesta por los m茅todos:\n",
    "\n",
    "- `possible_actions(state: State) -> Actions`: Encargado de generar todas las posibles acciones del problema, inclu铆da la acci贸n de conseguir el pl谩tano. Recibe el par谩metro `state` para determinar bajo qu茅 posici贸n se puede generar la acci贸n de conseguir el pl谩tano.\n",
    "\n",
    "- `choose_actions(self, state: State, goal: State) -> Actions`: Se encarga de determinar las posibles acciones que se pueden aplicar a un estado de partida `state` para generar un estado objetivo `goal`.\n",
    "\n",
    "La determinaci贸n de si una acci贸n es aplicable o no al estado `state` para generar el estado `goal` consiste en calcular la intersecci贸n entre las propiedades de la _lista de a帽adir_ de la acci贸n y las propiedades del estado `goal`. Si la intersecci贸n no es vac铆a entonces se considera que la acci贸n es v谩lida.\n",
    "\n",
    "Una vez determinadas las acciones aplicables, se ordena de mayor a menor nivel de eficiencia.\n",
    "\n",
    "El criterio seguido para determinar el nivel de eficiencia es el siguiente:\n",
    "\n",
    "1. Se consideran m谩s eficientes las acciones donde la suma de los pesos de las propiedades de la intersecci贸n resultante entre las propeidades del pseudo-estado que genera el estado `goal` a partir de aplicar la acci贸n analizada y las propiedades del estado de partida del problema es mayor.\n",
    "2. En caso de que haya acciones donde la primera condici贸n tenga el mismo valor, se tiene en cuenta primero aquellas acciones con mayor peso intr铆nseco.\n",
    "\n",
    "(Esta explicaci贸n queda m谩s clara viendo la implementaci贸n de los m茅todos `Heuristic.choose_actions` y `Heuristic._properties_weight` donde el primero determina y ordena en base al segundo m茅todo, las posibles acciones a realizar dado un estado de partida y un estado objetivo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pesos de acciones y propiedades\n",
    "\n",
    "Para ayudar a la heur铆stica a determinar qu茅 acciones son preferibles frente a otras, y de igual manera, qu茅 propiedades son prioritarias, se han asignado unos pesos a cada tipo de acci贸n y propiedad.\n",
    "\n",
    "#### Pesos de acciones\n",
    "\n",
    "Para resolver el problema se han creado cuatro tipos de acciones diferentes:\n",
    "\n",
    "- [`GetBanana`](cdalvaro/actions/get_banana.py) - Peso `4`: Se considera esta acci贸n como la prioritaria frente al resto. Lo que hace que cuando el mono est茅 sobre la caja, la acci贸n de conseguir el pl谩tano sea preferente a bajarse de nuevo de la caja.\n",
    "\n",
    "- [`ChangeLevel`](cdalvaro/actions/change_level.py) - Peso `3`: Este peso hace que la acci贸n de subirse a la caja sea preferente a que el mono vuelva a empujar la caja o se mueva por el suelo.\n",
    "\n",
    "- [`MoveHorizontally`](cdalvaro/actions/move_horizontally.py) - Peso `2`: Este peso hace que la acci贸n sea prioritaria frente a la acci贸n de mover la caja, lo que permite al planificador que una vez el mono ha alcanzado la caja no siga empuj谩ndola indefinidamente. Esto es as铆, porque el peso de las acciones se tiene en cuenta por detr谩s del peso de las propiedades, por lo que s贸lo sirve para evitar que el programa entre en bucles infinitos con el mono empujando incansablemente la caja.\n",
    "\n",
    "- [`PushBox`](cdalvaro/actions/push_box.py) - Peso `1`: La acci贸n de mover la caja es la que menor peso tiene frente al resto. De nuevo porque los pesos de las propiedades son preferentes. Esto hace que finalmente se elijan las acciones de mover la caja frente a las de movimiento. En definitiva, asignar el menor valor a la acci贸n evita que el programa entre en bucles infinitos en la planificaci贸n.\n",
    "\n",
    "**Nota**: Hay que tener en cuenta que el valor absoluto de los pesos no importa, s贸lo el valor relativo entre ellos para dar prioridad a unas acciones frente a otras.\n",
    "\n",
    "#### Pesos de propiedades\n",
    "\n",
    "Igual que con las acciones, existen tres propiedades de estados que modelizan el problema:\n",
    "\n",
    "- [`Has`](cdalvaro/properties/has.py) - Peso `0`: Esta propiedad no se prioriza frente a ninguna. Representa la propiedad de que un objeto posea otro, por ejemplo, que el mono tenga el pl谩tano.\n",
    "\n",
    "- [`AtLevel`](cdalvaro/properties/at_level.py) - Peso `0`: Esta propiedad tampoco se prioriza frente al resto. Simboliza la propiedad de que el mono est茅 en un nivel concreto.\n",
    "\n",
    "- [`AtPosition`](cdalvaro/properties/at_position.py) - Peso `?`: El peso de esta propiedad depende del elemento que tenga asignado:\n",
    "  \n",
    "  - Si el elemento de la propiedad es [`Banana()`](cdalvaro/element.py), el peso es `1`.\n",
    "  - Si el elemento de la propiedad es [`Monkey()`](cdalvaro/element.py), el peso es `2`.\n",
    "  - Si el elemento de la propiedad es [`Box()`](cdalvaro/element.py), el peso es `3`.\n",
    "\n",
    "De aqu铆 se ve que el mayor peso corresponde a la posici贸n de la caja, lo que hace que el mono intente desplazarse a la posici贸n de la caja lo antes posible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acciones\n",
    "\n",
    "Todas las acciones heredan de la clase [`BaseAction`](cdalvaro/actions/base_action.py). Que contiene un nombre `name` que identifica la acci贸n y un peso `weight`.\n",
    "\n",
    "Cada clase hija de la clase base debe implementar los m茅todos: `_set_precondition`, `_set_add_list` y `_set_remove_list` que definir谩n las propiedades de cada una de las listas de _precondici贸n, a帽adir y eliminar_ de la acci贸n representada respectivamente.\n",
    "\n",
    "Adem谩s la clase `BaseAction` implementa los m茅todos:\n",
    "\n",
    "- `can_apply(self, state: State, reverse: bool) -> bool`: que permite determinar si se puede aplicar una acci贸n sobre un estado dado. O saber si podr铆a obtenerse un estado v谩lido a partir de revertir la acci贸n sobre el estado `state`.\n",
    "\n",
    "- `apply(self, state: State, reverse: bool = False) -> Union[State, None]`: para obtener el estado resultante de aplicar la acci贸n sobre el estado `state`, o para obtener el _pseudo-estado_ que generar铆a el estado `state` a partir de revertir la acci贸n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propiedades\n",
    "\n",
    "La clase [`BaseProperty`](cdalvaro/properties/base_property.py) modeliza una propiedad de estado.\n",
    "\n",
    "Como se ha visto ya, las clases hijas se usar谩n para definir las propiedades de los estados y de las acciones del problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "Como ha podido verse en la secci贸n [Plan encontrado](#Plan-encontrado), la soluci贸n encontrada al problema es 贸ptima. El mono se desplaza en un s贸lo movimiento a la posici贸n de la caja, la empuja a la posici贸n del pl谩tano en un solo movimiento, trepa y consigue el pl谩tano. _Cuatro movimientos en total._\n",
    "\n",
    "Puede verse, que si se desactiva la heur铆stica _eficiente_ estableciendo `Strips.efficiency_limit = 0` el mono puede encontrar la soluci贸n 贸ptima o no. _Pero, al final acaba encontrando una soluci贸n viable._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "AVISO: La heur铆stica no est谩 encontrando soluciones eficientes\nPlan encontrado \n  1. Mueve  de 1 a 2\n  2. Mueve  de 2 a 3\n  3.  empuja la  de 3 a 2\n  4.  empuja la  de 2 a 3\n  5.  empuja la  de 3 a 2\n  6.  empuja la  de 2 a 3\n  7. Mueve  de 3 a 1\n  8. Mueve  de 1 a 2\n  9. Mueve  de 2 a 3\n  10.  empuja la  de 3 a 1\n  11.  empuja la  de 1 a 2\n  12.  empuja la  de 2 a 1\n  13.  empuja la  de 1 a 2\n  14. Cambia  al nivel Superior en posici贸n 2\n  15.  consigue  en posici贸n 2\n"
    }
   ],
   "source": [
    "get_plan(planner, optimal_solution=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otro lado, a continuaci贸n se presentan otros ejemplos, algunos m谩s sencillos, otros m谩s complicados para mostrar la versatilidad del algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condici贸n inicial alternativa 1\n",
    "\n",
    "El mono comienza ubicado en el suelo, en la misma posici贸n que la caja, y en distinta posici贸n que el pl谩tano.\n",
    "\n",
    "En este caso, el mono s贸lo deber铆a empujar la caja a la posici贸n del pl谩tano, subirse sobre ella y conseguir su objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Plan encontrado \n  1.  empuja la  de 1 a 2\n  2. Cambia  al nivel Superior en posici贸n 2\n  3.  consigue  en posici贸n 2\n"
    }
   ],
   "source": [
    "initial_state = State({\n",
    "    AtPosition(Monkey(), 1),\n",
    "    AtLevel(Monkey(), GroundLevel()),\n",
    "    AtPosition(Banana(), 2),\n",
    "    AtPosition(Box(), 1)\n",
    "})\n",
    "\n",
    "planner = Strips(initial_state, goal_state, Heuristic(initial_state))\n",
    "get_plan(planner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condici贸n inicial alternativa 2\n",
    "\n",
    "Ahora, el mono comienza subido sobre la caja en una posici贸n distinta a la ubicaci贸n del pl谩tano.\n",
    "\n",
    "En la soluci贸n 贸ptima, el mono tendr谩 que bajarse de la caja, empujarla a la posici贸n del pl谩tano, trepar por ella y conseguir el pl谩tano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Plan encontrado \n  1. Cambia  al nivel Inferior en posici贸n 1\n  2.  empuja la  de 1 a 2\n  3. Cambia  al nivel Superior en posici贸n 2\n  4.  consigue  en posici贸n 2\n"
    }
   ],
   "source": [
    "initial_state = State({\n",
    "    AtPosition(Monkey(), 1),\n",
    "    AtLevel(Monkey(), TopLevel(), 1),\n",
    "    AtPosition(Banana(), 2),\n",
    "    AtPosition(Box(), 1)\n",
    "})\n",
    "\n",
    "planner = Strips(initial_state, goal_state, Heuristic(initial_state))\n",
    "get_plan(planner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condici贸n inicial alternativa 3\n",
    "\n",
    "Por 煤ltimo, probamos la situaci贸n en la que el mono, la caja y el pl谩tano est谩n en la misma posici贸n y el mono est谩 en el nivel inferior.\n",
    "\n",
    "En este caso el mono s贸lo deber谩 trepar por la caja y conseguir el pl谩tano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Plan encontrado \n  1. Cambia  al nivel Superior en posici贸n 2\n  2.  consigue  en posici贸n 2\n"
    }
   ],
   "source": [
    "initial_state = State({\n",
    "    AtPosition(Monkey(), 2),\n",
    "    AtLevel(Monkey(), GroundLevel()),\n",
    "    AtPosition(Banana(), 2),\n",
    "    AtPosition(Box(), 2)\n",
    "})\n",
    "\n",
    "planner = Strips(initial_state, goal_state, Heuristic(initial_state))\n",
    "get_plan(planner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede verse, en todos los casos, la heur铆stica consigue encontrar la soluci贸n 贸ptima (salvo en el caso en el que se ha desactivado expl铆citamente).\n",
    "\n",
    "Es muy interesante ver, c贸mo este sistema de propiedades de estados donde s贸lo se tienen en cuenta propiedades parciales, permite generar una planifiaci贸n para alcanzar el objetivo propuesto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python37764bitec668b5d4c5e465891db50f9b9e698e1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}